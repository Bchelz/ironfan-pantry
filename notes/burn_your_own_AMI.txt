service chef-client stop
ps auxf
df -BG
#
away_dir=/tmp/ami_away
mkdir -p "$away_dir"
cd /tmp

# Tidy up the joint for the next occupants
apt-get -y update  ;
apt-get -y upgrade ;
apt-get -f install ;
apt-get clean ;
updatedb ;

# move away anything tied to the identity of this machine
mv /etc/hostname /etc/node*name /var/www/index.html "$away_dir"
# move away chef junk
mv /var/chef /etc/chef/{*.json,*.pem,*~} "$away_dir"

# make a nice bland motd
. /etc/lsb-release 
img_info="  infochimps-$DISTRIB_CODENAME-`uname -i`-`ruby --version | cut -d' '  -f2`-`date +"%Y%m%d-%H"`"
rm /etc/motd ;
echo "CHIMP CHIMP CHIMP CRUNCH CRUNCH CRUNCH (image burned at `date`): $img_info" > /etc/motd;

# unmount your mountables
cd / ; for foo in /home /ebs* /data/ebs* /data ; do umount $foo 2>/dev/null ; done

# zero out all files in /var/log
cd /var/log ; for foo in `find /var/log -type f` ; do echo $foo ; bash -c "echo -n > $foo"  ; done

echo "Done!"
echo ""
echo "Go to the console; hit 'stop' on the machine, count to a hundred,"
echo "then hit 'Create Image (EBS AMI)'. Name the AMI something like"
echo ""
echo "  $img_info"
echo ""

___________________________________________________________________________

OLDER stuff below

___________________________________________________________________________

## Burn an AMI 

# Fix:
#  /etc/hosts
#  /etc/hostname
#  /etc/fstab

# Nuke files that would be inconvenient to persist: chef config and startup files; log files; and files that contain keys of some sort.
sudo true
away_dir=/mnt/tmp/away-`date "+%Y%m%d%H"`
sudo mkdir -p $away_dir

sudo service chef-client stop
ps auxf
df -BG

# Give apt some last-minute lovin'
sudo apt-get -y update  ;
sudo apt-get -y upgrade ;
sudo apt-get -f install ;
sudo apt-get clean ;
sudo updatedb ;

sudo mv /var/chef /etc/hostname /etc/node*name /etc/chef/{client-config.json,first-boot.json,node-attrs.json,chef-config.json,*.pem,*~} /var/www/index.html $away_dir
sudo rm -rf /var/cache/chef/*
# flush files that might have history or credentials
sudo rm -rf /root/{.cache,.chef,emacs.d,.bash_history,.gem} ~ubuntu/{.cache,.chef,emacs.d,.bash_history,.gem} /var/backups/*
# Zero out log files
sudo rm -rf /var/lib/cloud/data/* /var/log/{chef,hadoop,rabbitmq,cassandra,nginx,elasticsearch}/* /etc/sv/*/log/main/* /var/log/*.gz
sudo bash -c 'for foo in /var/log/{dmesg,syslog,messages,debug,udev,lastlog,faillog,dmesg.0,*.log} ; do echo -n > $foo ; done'
# If you want to record the AMI version, something like
sudo rm /etc/motd ;
sudo bash -c 'echo "CHIMP CHIMP CHIMP CRUNCH CRUNCH CRUNCH (image burned at `date`)" > /etc/motd ' ;

# Shutdown services  and make the following ones not restart on bootup
for foo in hadoop-0.20-{namenode,jobtracker,tasktracker,datanode,secondarynamenode} hadoop-{zookeeper-server,hbase-master,hbase-regionserver} cassandra couchdb thttpd nfs-kernel-server god apeyeye nginx  rabbitmq-server chef-{solr,solr-indexer,client,server,server-webui} elasticsearch ; do sudo service $foo stop ; done
killall redis-server tail nginx console-kil-daemon
for foo in thttpd hadoop-0.20-{tasktracker,datanode,namenode,jobtracker,secondarynamenode} hadoop-{zookeeper-server,hbase-master,hbase-regionserver} cassandra elasticsearch ; do sudo update-rc.d -f $foo remove ; done
# Give the process list a hows-your-father -- nothing interesting should be running.
ps auxf
# Unmount anything that's mounted,
sudo umount /home
sudo umount /ebs*
# Detatch anything that's attached,
ec2-describe-volumes -K pk.pem -C cert.pem | grep 3045e85a
ec2-detach-volume    -K pk.pem -C cert.pem vol-123545
# and check that it all worked.
mount
ec2-describe-volumes -K pk.pem -C cert.pem | grep 3045e85a
# nuke user accts
for foo in flip jacob dhruv doncarlo jesse dsnyder howech ryan nickster robochimp joe deploy instiki integrity webservers ; do sudo userdel $foo ; sudo groupdel $foo ; done
# blow away anything git-deployed
sudo rm -rf /var/www/{apeyeye,apidocs} /etc/{apeyeye,god,monitoring,redis,elasticsearch} /var/run/god /var/log/god /etc/sv/apeyeye
# Move files out of the way that will confuse on reboot
sudo mv /var/lib/couchdb/0.10.0/chef.couch /var/lib/rabbitmq/mnesia/rabbit /srv/chef/cache/chef_server_cookie_id /etc/hadoop/conf/{*.xml,raw_settings.yaml*} /etc/cassandra/storage-conf* /etc/elasticsearch/* $away_dir
</code></pre>

h3. Burning an EBS-backed AMI

Just use the console. MAKE SURE TO STOP, UNMOUNT AND DETACH ALL EBS volumes first.

  infochimps.chef-client.maverick.east.ebs-64bit-20110703
  ClusterChef client 20110703 http://github.com/infochimps/cluster_chef - System orchestration with Chef
  
h3. Burning an Instance-backed (s3) AMIs

From your local machine, bring over your credentials

<pre><code>
  cluster=hoolock
  scp -i ~/.hadoop-ec2/keypairs/hoolock.pem ~/.hadoop-ec2/{certs/cert.pem,certs/pk.pem,keypairs/hoolock.pem} ubuntu@50.16.13.146:/tmp
</code></pre>

On the target machine:

<pre><code>
cd /mnt
eval $(sudo blkid /dev/sda1 | awk -F: '{ print $2 }') 
# credentials
AWS_ACCOUNT_ID=123456781234 AWS_ACCESS_KEY_ID=2341245 AWS_SECRET_ACCESS_KEY=125324635473465743674637
# ... move the keys to /mnt (so that they are ignored in the bundling)
sudo mv /tmp/*.pem /mnt
</code></pre>
  
Modify the following to suit. (A note about AMI_EXCLUDES: the ec2-bundle-vol
will complain about excluded dirs that don't exist -- remove those. Be careful
though, because it is a VERY BAD THING if directories that do exist (say, a
500GB attached drive) aren't excluded!)

<pre><code>

# edit these:
# i386 or x86_64
BITS=x86_64
# might need to add: /ebs1,/ebs2,/data,/var/lib/cassandra,/srv/chef/cache
AMI_EXCLUDES=/mnt,/mnt2,/root/.ssh/authorized_keys,/home/ubuntu/.ssh/authorized_keys

export EC2_CERT=/mnt/cert.pem
export EC2_PRIVATE_KEY=/mnt/pk.pem
kern=$(wget -q http://169.254.169.254/latest/meta-data/kernel-id -O -) ; echo $kern
eval `cat /etc/lsb-release `
AMI_BUCKET=s3amis.infinitemonkeys.info
ami_name=infochimps.chef-client.${DISTRIB_CODENAME}.east.ami-${BITS}-`date "+%Y%m%d"`
ami_bucket=${AMI_BUCKET}/$ami_name
sudo mkdir -p /mnt/$ami_bucket

# This will take a long fucking time (15 minutes on a small instance) so treat yourself to a large CPU-heavy machine when you're burninating
time sudo ec2-bundle-vol --kernel $kern --exclude=$AMI_EXCLUDES -r $BITS -d /mnt/$ami_bucket -u $AWS_ACCOUNT_ID --cert cert.pem --privatekey pk.pem --ec2cert /etc/ec2/amitools/cert-ec2.pem

( cd /mnt/$ami_bucket ; ec2-unbundle --manifest image.manifest.xml --destination /mnt --privatekey $EC2_PRIVATE_KEY  )

time ec2-bundle-image --image /mnt/image --kernel $kern -u $AWS_ACCOUNT_ID --cert cert.pem --privatekey pk.pem --ec2cert /etc/ec2/amitools/cert-ec2.pem

time ec2-upload-bundle    -b $ami_bucket -m /mnt/$ami_bucket/image.manifest.xml -a $AWS_ACCESS_KEY_ID -s $AWS_SECRET_ACCESS_KEY
time ec2-register -n $ami_name -d $ami_name $ami_bucket/image.manifest.xml
</code></pre>

h4. If you are in a region other than us-east-1

# export AWS_REGION=us-west-1 
# export EC2_URL=https://${AWS_REGION}.ec2.amazonaws.com
# sudo mkdir -p /mnt/$ami_bucket
# time sudo ec2-bundle-vol --exclude=$AMI_EXCLUDES -d /mnt/$ami_bucket -u $AWS_ACCOUNT_ID --cert cert.pem --privatekey pk.pem --ec2cert /etc/ec2/amitools/cert-ec2.pem
# time ec2-migrate-manifest      --manifest /mnt/$ami_bucket/image.manifest.xml   --region   $AWS_REGION -a $AWS_ACCESS_KEY_ID -s $AWS_SECRET_ACCESS_KEY 
# time ec2-upload-bundle    -b $ami_bucket -m /mnt/$ami_bucket/image.manifest.xml --location $AWS_REGION -a $AWS_ACCESS_KEY_ID -s $AWS_SECRET_ACCESS_KEY
# time ec2-register -n $ami_name -d $ami_name $ami_bucket/image.manifest.xml      --region $AWS_REGION

