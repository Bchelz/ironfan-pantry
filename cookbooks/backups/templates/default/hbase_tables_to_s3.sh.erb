#!/usr/bin/env bash

clusterName="<%= @node[:backups][:hbase][:cluster_name] %>"
start=""
end=""
dt=$(date +%Y%m%d)
workDir="<%= @node[:backups][:location] %>/${clusterName}-hbase-${dt}"
s3Target="s3://<%= @node[:backups][:s3] %>/hbase_backups/${dt}/"
hbaseTables="<%= @node[:backups][:hbase][:tables].join(" ") %>"
versions=<%= @node[:backups][:hbase][:versions] %>
full_bkups=<%= @node[:backups][:hbase][:full_backup] %>
type=""

if [ -f "/tmp/hbase_backup.lock" ]; then
  echo "Lock file in place. Exiting"
  exit -1
fi

lock="/tmp/hbase_backup.lock"

echo "$$: $(date +%s)" > ${lock}

if [ -z ${clusterName} ]; then
    clusterName="hbase"
fi

if [ ! -d ${workDir} ]; then
    mkdir -p ${workDir}
fi

day=$(date +%A)
if [ ${day} == ${full_bkups} ]; then 
  type="full"
  start=0
else
  type="differential"
  start=$(date -d "last-${full_bkups}" +%s)
fi

for table in ${hbaseTables}; do 
    hbase org.apache.hadoop.hbase.mapreduce.Export -D mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec -D mapred.output.compression.type=BLOCK -D mapred.output.compress=true ${table} /tmp/${table}_backup.${dt} ${versions} ${start}; 

    if [ ! -d ${workDir}/${table}-${type} ]; then
        mkdir ${workDir}/${table}-${type}
    fi 

    hadoop fs -get /tmp/${table}_backup.${dt}/part-* ${workDir}/${table}-${type}/
    hadoop fs -rmr /tmp/${table}_backup.${dt}

    for file in ${workDir}/${table}-${type}/part*; do 
      mv ${file} ${file}.snappy
    done 
done 

s3cmd --recursive put ${workDir}/ ${s3Target}
rm -r ${workDir}/*

rm ${lock}

exit 0
